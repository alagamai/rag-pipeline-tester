#!/bin/bash

echo "--------------------------------------"
echo "üß© RAG + Ollama Environment Setup"
echo "--------------------------------------"

PROJECT_ROOT="$(pwd)"
VENV_PATH="$PROJECT_ROOT/.rag_env"

echo "üìÅ Project root: $PROJECT_ROOT"


# ----------------------------------------------------
# 1Ô∏è‚É£ Create/Activate Virtual Environment
# ----------------------------------------------------
if [ ! -d "$VENV_PATH" ]; then
    echo "üß± Creating virtual environment (.rag_env)..."
    python3 -m venv "$VENV_PATH"
else
    echo "‚úÖ Virtual environment already exists."
fi

echo "üì¶ Activating environment..."
source "$VENV_PATH/bin/activate"


# ----------------------------------------------------
# 2Ô∏è‚É£ Verify/Install Ollama
# ----------------------------------------------------
echo "üîç Checking for Ollama..."

if ! command -v ollama &> /dev/null; then
    echo "‚öôÔ∏è Ollama not found. Installing using Homebrew..."
    brew install ollama
else
    echo "‚úÖ Ollama is already installed."
fi


# ----------------------------------------------------
# 3Ô∏è‚É£ Start Ollama server if not running
# ----------------------------------------------------
echo "üöÄ Starting Ollama server..."

# kill old instance
PID=$(lsof -ti tcp:11434)
if [ ! -z "$PID" ]; then
    echo "üßπ Stopping old Ollama service..."
    kill -9 "$PID"
fi

# start fresh
ollama serve &

# wait for server
echo "‚è≥ Waiting for Ollama to start..."
sleep 3

# check API
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "‚úÖ Ollama server is running."
else
    echo "‚ùå ERROR: Ollama server is not responding."
    echo "üëâ Try running: ollama serve"
    exit 1
fi


# ----------------------------------------------------
# 4Ô∏è‚É£ Install Python Libraries Needed for RAG
# ----------------------------------------------------
echo "üì¶ Installing RAG dependencies..."

pip install --upgrade pip

pip install \
    langchain \
    langchain-core \
    langchain-community \
    langchain-text-splitters \
    langchain-ollama \
    chromadb \
    pypdf \
    python-dotenv \
    streamlit

# ----------------------------------------------------
# 5Ô∏è‚É£ Pull Required Ollama Models
# ----------------------------------------------------
echo "üì• Pulling Ollama models..."

ollama pull mxbai-embed-large
ollama pull llama3.1


# ----------------------------------------------------
# 6Ô∏è‚É£ Verify Setup (LLM + Embedding)
# ----------------------------------------------------
echo "‚úÖ Verifying final setup..."

python - <<EOF
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaLLM
print("‚úÖ LangChain + Chroma + Ollama stack is working.")
EOF


echo "--------------------------------------"
echo "‚úÖ RAG Setup Complete"
echo "Activate environment with:"
echo "   source .rag_env/bin/activate"
echo "Run your RAG demo with:"
echo "   python rag_simple.py"
echo "--------------------------------------"

